{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "\n",
    "from src.dataset.dataset import DaggerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_path = Path(\"/data/scratch/ankile/furniture-data/processed/diffik/sim/one_leg/teleop/low/success.zarr\")\n",
    "out_path = Path(\"/scratch/furniture-data/processed/diffik/sim/one_leg/teleop/low/success.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input zarr store and create the output zarr store\n",
    "source = zarr.open(inp_path)\n",
    "target = zarr.open(out_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/episode_ends' (25,) uint32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy over `robot_state`, `action/pos`, `episode_ends` arrays as is\n",
    "target.create_dataset('robot_state', data=source['robot_state'], chunks=source['robot_state'].chunks)\n",
    "target.create_dataset('action', data=source['action/pos'], chunks=source['action/pos'].chunks)\n",
    "target.create_dataset('episode_ends', data=source['episode_ends'], chunks=source['episode_ends'].chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.28it/s]\n",
      "100%|██████████| 12/12 [00:05<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy over `color_image1` and `color_image2` arrays by loading a chunk at a time and writing to the output store with chunksize 1 along the first axis\n",
    "for key in ['color_image1', 'color_image2']:\n",
    "    source_array = source[key]\n",
    "    target_array = target.create_dataset(key, shape=source_array.shape, chunks=(1, *source_array.shape[1:]), dtype=source_array.dtype)\n",
    "\n",
    "    # Iterate over the source array and copy over whole chunks to the target array\n",
    "    for i in trange(0, source_array.shape[0], source_array.chunks[0]):\n",
    "        target_array[i:i+source_array.chunks[0]] = source_array[i:i+source_array.chunks[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action', 'color_image1', 'color_image2', 'episode_ends', 'robot_state']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(target.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DaggerDataset' object has no attribute 'action_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m norm \u001b[38;5;241m=\u001b[39m LinearNormalizer()\n\u001b[1;32m      5\u001b[0m norm\u001b[38;5;241m.\u001b[39mfit({\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrobot_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: source[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobot_state\u001b[39m\u001b[38;5;124m'\u001b[39m][:],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction/pos\u001b[39m\u001b[38;5;124m\"\u001b[39m: source[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction/pos\u001b[39m\u001b[38;5;124m'\u001b[39m][:],\n\u001b[1;32m      8\u001b[0m })\n\u001b[0;32m---> 11\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDaggerDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobs_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/scratch/ankile/robust-rearrangement/src/dataset/dataset.py:675\u001b[0m, in \u001b[0;36mDaggerDataset.__init__\u001b[0;34m(self, dataset_path, pred_horizon, obs_horizon, action_horizon, normalizer, control_mode, predict_past_actions)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_ends \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_ends\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length \u001b[38;5;241m=\u001b[39m obs_horizon \u001b[38;5;241m+\u001b[39m pred_horizon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobot_state_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrobot_state\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_action_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predict_past_actions \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_horizon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DaggerDataset' object has no attribute 'action_key'"
     ]
    }
   ],
   "source": [
    "from src.dataset.normalizer import LinearNormalizer\n",
    "\n",
    "\n",
    "norm = LinearNormalizer()\n",
    "norm.fit({\n",
    "    \"robot_state\": source['robot_state'][:],\n",
    "    \"action/pos\": source['action/pos'][:],\n",
    "})\n",
    "\n",
    "\n",
    "dataset = DaggerDataset(\n",
    "    dataset_path=out_path,\n",
    "    action_horizon=8,\n",
    "    obs_horizon=1,\n",
    "    pred_horizon=32,\n",
    "    normalizer=norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 10]),\n",
       " torch.Size([1, 240, 320, 3]),\n",
       " torch.Size([1, 240, 320, 3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"action\"].shape, dataset[0][\"color_image1\"].shape, dataset[0][\"color_image2\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.episode_ends[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
